---
title: "Tutorial for spVarBayes"
author: "Jiafang Song"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial for spVarBayes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(spVarBayes)
library(ggplot2)
library(RANN)
```

## Overview

`spVarBayes` provides scalable Bayesian inference for spatial data using Variational Bayes (VB) and Nearest Neighbor Gaussian Processes (NNGP). All methods are designed to work efficiently even with 100,000 spatial locations, offering a practical alternative to traditional MCMC. It includes:

- **Mean Field Approximation (MFA)** and its **Linear Response (LR)** correction
- **NNGP** variational distributions for spatial random effects
- **Joint variational distributions** for regression coefficients and spatial effects


## Installation

The package is available on the github. To install this package in your R, you can use the code: `devtools::install_github("jfsong100/spVarBayes")`. Once installed, you can

```{r}
library(spVarBayes)
```


This tutorial walks through generating data, fitting each method, and making predictions.

## Simulate Data
```{r}
rmvn <- function(n, mu=0, V = matrix(1)){
  p <- length(mu)
  if(any(is.na(match(dim(V),p))))
    stop("Dimension problem!")
  D <- chol(V)
  t(matrix(rnorm(n*p), ncol=p)%*%D + rep(mu,rep(n,p)))
}

set.seed(1010)
n <- 1500

coords <- cbind(runif(n,0,5), runif(n,0,5))

# Remove close points
remove_close_points <- function(x, y, threshold) {

  points <- cbind(x, y)
  
  repeat {
    neighbors <- nn2(data = points, k = 2, searchtype = "radius", radius = threshold)
    distances <- neighbors$nn.dists[, 2]
    if (all(is.na(distances) | distances >= threshold)) {
      break 
    }
    closest_index <- which.min(distances)
    points <- points[-closest_index, ]
  }
  
  list(x = points[, 1], y = points[, 2])
}

remove_coords <- remove_close_points(coords[,1], coords[,2], 0.015)
cleaned_x <- remove_coords$x
cleaned_y <- remove_coords$y

coords <- cbind(cleaned_x,cleaned_y)

n = nrow(coords)

x <- cbind(rnorm(n), rnorm(n))
B <- as.matrix(c(1,5))

sigma2_true <- 5
tau2_true <- 1
phi_true <- 6

D <- as.matrix(dist(coords))
R <- exp(-phi_true*D)
w <- rmvn(1, rep(0,n), sigma2_true*R)
y <- rnorm(n, x%*%B + w, sqrt(tau2_true))

# Split into training set and test set
n_train <- 1000
train_index <- sample(1:n, n_train)
y_train <- y[train_index]
x_train <- x[train_index,]
w_train <- w[train_index,]
coords_train <- coords[train_index,]

y_test <- y[-train_index]
x_test <- x[-train_index,]
w_test <- w[-train_index,]
coords_test <- coords[-train_index,]

```

## Fit NNGP

```{r, fig.align = "center", fig.width = 6, fig.height = 6}
NNGP <- spVB_NNGP(y = y_train,X = x_train,coords=coords_train, n.neighbors = 15, 
                       n.neighbors.vi = 3,
                       rho = 0.85, max_iter = 1500, covariates = TRUE)
w_var_NNGP <- spVB_get_Vw(NNGP)
```

### Sampling and prediction

```{r, fig.align = "center", fig.width = 6, fig.height = 6}
NNGP_w_samples <- spVB_w_sampling(NNGP, n.samples = 5000)$p.w.samples
NNGP_predict <- predict(NNGP, coords.0 = coords_test, X.0 = x_test, covariates = TRUE, n.samples = 5000)
```

## Fit NNGP joint model
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
NNGP_joint <- spVB_NNGP(y = y_train,X = x_train,coords=coords_train, n.neighbors = 15, 
                        n.neighbors.vi = 3,
                        rho = 0.85, max_iter = 1500, covariates = TRUE, joint = TRUE)

w_var_NNGP_joint <- spVB_get_Vw(NNGP_joint)
```

### Sampling and prediction
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
NNGP_joint_w_samples <- spVB_joint_sampling(NNGP_joint, n.samples = 5000)$p.w.samples
NNGP_joint_predict <- predict(NNGP_joint, coords.0 = coords_test, X.0 = x_test, covariates = TRUE, n.samples = 5000)


```



## Fit MFA
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
MFA <- spVB_MFA(y = y_train,X = x_train,coords=coords_train, covariates = TRUE, 
                n.neighbors = 15, rho = 0.85, max_iter = 1000, LR = FALSE)
```

### Sampling and prediction
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
MFA_w_samples <- spVB_w_sampling(MFA, n.samples = 5000)$p.w.samples
MFA_predict <- predict(MFA, coords.0 = coords_test, X.0 = x_test, covariates = TRUE, n.samples = 5000)

```



## Fit MFA with linear response
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
MFA_LR <- spVB_MFA(y = y_train,X = x_train,coords=coords_train, covariates = TRUE, 
                   n.neighbors = 15, rho = 0.85, max_iter = 1000, LR = TRUE)

```

### Sampling and prediction
```{r, fig.align = "center", fig.width = 6, fig.height = 6}
MFA_LR_w_samples <- spVB_LR_sampling(MFA_LR, n.samples = 5000)$p.w.samples
MFA_LR_predict <- predict(MFA_LR, coords.0 = coords_test, X.0 = x_test, covariates = TRUE, n.samples = 5000)


```


## Compare with spNNGP

```{r, fig.align = "center", fig.width = 6, fig.height = 6, warning = FALSE, message = FALSE}
n.samples = 5000
starting <- list("phi"= 5, "sigma.sq"=1, "tau.sq"= 0.5)
tuning <- list("phi"=0.15, "sigma.sq"=1.5, "tau.sq"=1.15)
priors <- list("phi.Unif"=c(1/10, 10), "sigma.sq.IG"=c(0.1, 1), "tau.sq.IG"=c(1,1))
cov.model <- "exponential"

library(spNNGP)
intercept = rep(1,n)
m.s <- spNNGP(y_train~x_train-1, coords=coords_train, starting=starting, method="latent",
              n.neighbors=15, priors=priors, tuning=tuning, cov.model=cov.model,
              n.samples=n.samples, n.omp.threads=1, n.report=1000)

burnin = 2000

summary(m.s)
what = apply(m.s$p.w.samples[,((burnin+1):n.samples)], 1, mean)
wvarhat = apply(m.s$p.w.samples[,((burnin+1):n.samples)], 1, var)

spNNGP_predict <- predict(m.s, coords.0 = coords_test, X.0 = x_test, n.samples = 5000)

```

### Compare the posterior mean with true value

```{r, fig.align = "center", fig.width = 6, fig.height = 6}
df_means <- data.frame(
  true = rep(w_train, 5),
  est = c(
    NNGP$w_mu[order(NNGP$ord)],
    NNGP_joint$w_mu[order(NNGP_joint$ord)],
    MFA$w_mu[order(MFA$ord)],
    MFA_LR$w_mu[order(MFA_LR$ord)],
    what
  ),
  method = rep(c(
    "spVB-NNGP",
    "spVB-NNGP Joint",
    "spVB-MFA",
    "spVB-MFA Linear Response",
    "spNNGP"
  ), each = length(w_train))
)

ggplot(df_means, aes(x = true, y = est)) +
  geom_point(alpha = 0.7, size = 1.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", linewidth = 1) +
  facet_wrap(~ method, ncol = 3) +
  labs(
    x = "True spatial random effect (w)",
    y = "Estimated posterior mean (w)",
    title = "Posterior Mean vs. True Spatial Random Effect Across Methods"
  ) +
  coord_fixed() +
  theme_minimal(base_size = 12)+
  theme(
    plot.title = element_text(size = 11, hjust = 0.5)
  )

```


### Compare the predicted mean with true value

```{r, fig.align = "center", fig.width = 6, fig.height = 6}
df_test <- data.frame(
  true = rep(w_test, 5),
  est = c(
    apply(NNGP_predict$p.w.0, 1, mean),
    apply(NNGP_joint_predict$p.w.0, 1, mean),
    apply(MFA_predict$p.w.0, 1, mean),
    apply(MFA_LR_predict$p.w.0, 1, mean),
    apply(spNNGP_predict$p.w.0, 1, mean)
  ),
  method = rep(c(
    "spVB-NNGP",
    "spVB-NNGP Joint",
    "spVB-MFA",
    "spVB-MFA Linear Response",
    "spNNGP"
  ), each = length(w_test))
)

ggplot(df_test, aes(x = true, y = est)) +
  geom_point(alpha = 0.7, size = 1.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", linewidth = 1) +
  facet_wrap(~ method, ncol = 3) +
  labs(
    x = "True spatial random effect (w)",
    y = "Predicted posterior mean (w)",
    title = "Predicted vs. True Spatial Random Effect (Test Set)"
  ) +
  coord_fixed() +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 11, hjust = 0.5)
  )

```

### Compare the posterior variance with spNNGP

```{r, fig.align = "center", fig.width = 6, fig.height = 6}
df_all <- data.frame(
  ref = rep(wvarhat, 4),
  est = c(
    diag(w_var_NNGP)[order(NNGP$ord)],
    diag(w_var_NNGP_joint)[-(1:ncol(x_train))][order(NNGP_joint$ord)],
    MFA$w_sigma_sq[order(MFA$ord)],
    diag(MFA_LR$updated_mat)[-(1:ncol(x_train))][order(MFA_LR$ord)]
  ),
  method = rep(c("spVB-NNGP", "spVB-NNGP Joint", "spVB-MFA", "spVB-MFA Linear Response"),
               each = length(wvarhat))
)

ggplot(df_all, aes(x = ref, y = est)) +
  geom_point(alpha = 0.7, size = 1.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", linewidth = 1) +
  facet_wrap(~ method, ncol = 2) +
  labs(
    x = "Estimated variance using spNNGP",
    y = "Estimated variance using method",
    title = "Comparison of Estimated Variance Across Methods"
  ) +
  coord_fixed() +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 11, hjust = 0.5)
  )

```

### Compare the estimated mean for spatial parameters

```{r}
theta_est <- matrix(c(
  MFA$theta,
  MFA_LR$theta,
  NNGP$theta,
  NNGP_joint$theta,
  colMeans(m.s$p.theta.samples[-(1:burnin), ])
), nrow = 3)

rownames(theta_est) <- c("sigmasq", "tausq", "phi")
colnames(theta_est) <- c("spVB-MFA", "spVB-MFA LR", "spVB-NNGP", "spVB-NNGP Joint", "spNNGP")

theta_est

```
### Compare the estimated mean and variance for regression coefficients

```{r}
beta_est <- matrix(rbind(cbind(
  MFA$beta,
  MFA_LR$beta,
  NNGP$beta,
  NNGP_joint$beta,
  colMeans(m.s$p.beta.samples[-(1:burnin), ])
),cbind(
  diag(MFA$beta_cov),
  diag(MFA_LR$updated_mat)[1:ncol(x_train)],
  diag(NNGP$beta_cov),
  diag(w_var_NNGP_joint)[1:ncol(x_train)],
  apply(m.s$p.beta.samples[-(1:burnin),], 2, var)
)),nrow = 4)

rownames(beta_est) <- c("beta1.mean", "beta2.mean", "beta1.var", "beta2.var")
colnames(beta_est) <- c("spVB-MFA", "spVB-MFA LR", "spVB-NNGP", "spVB-NNGP Joint", "spNNGP")

beta_est

```
